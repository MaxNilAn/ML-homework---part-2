#!/usr/bin/env python
# coding: utf-8

# # Машинное обучение

# ## ML решает следующую задачу
# Требуется подогнать заданный набор точек, представляющих данные, 
# под соответствующую функцию (отображение входа на выход), 
# которая улавливает важные сигналы в данных и игнорирует помехи, 
# а затем убедиться, что на новых данных найденная функция работает "хорошо".

# - Есть набор данных
# - Данные поступают на вход некоторого процесса (обучение)
# - В результате получается модель
# - Предсказание: на вход поступает модель и исходные данные, получается результат 1
# - Если результат 1 нас устраивает, модель признается успешной
# - Приходят новые данные, которые идут в процедуру предсказания вместе с прошлой моделью, получется результат 2

# **Пример про посещение магазина:** природа задачи такова, что входные данные примерно одни и те же (голод),
# поэтому можно предположить, что в среднем получается одно и то же
# 
# **Пример про матчи:** другой источник данных, другое распределение

# ### Источник данных (смысл задачи) влияет на построение модели
# ### Обосновать применимость результата нельзя

# ## Виды машинного обучения
# - Обучение с учителем (supervised learning)
# - Обучение без учителя (unsupervised learning)

# ### Обучение с учителем
# Моделирует отношение между признаками и метками
# 
# Такие модели служат для предсказания меток на основе обучающих маркированных данных.
# После построения модели можно использовать ее для присвоения меток новым ранее неизвестным данным.
# 
# - задачи классификации (метки - дискретные: два или более)
# - задачи регрессии (метки/результат - непрерывные величины)

# ### Обучение без учителя
# Моделирует призники без меток.
# 
# Такие модели служат для выявления структуры немаркированных данных.
# 
# - задачи кластеризации (выделяет отдельные группы данных)
# - задачи понижения размерности (поиск более сжатого представления данных, убирается избыточность)

# ### Существуют методы частичного обучения (semi-supervised learning)
# Не все данные промаркированы

# ### Методы обучения с подкреплением (reinforcement learning)
# Система обучения улучшает свои характеристики на основе взаимодействия (обратной связи) со средой.
# При этом взаимодействии система получает сигналы (функции наград), которые несут в себе информацию,
# насколько хорошо система решила задачу (с точки зрения среды, в которой она работает).
# Это продолжается, пока итоговая награда не станет максимальной.

# In[62]:


import seaborn as sns

iris = sns.load_dataset('iris')

print(iris.head())
print(type(iris),type(iris.values))

print(iris.values.shape)
print(iris.columns)
print(iris.index)


# ### Терминология
# - Строки - отдельные объекты - образцы (sample)
# - Столбцы - признаки - соответствует конкретным наблюдениям
# - Матрицы признаков (features matrix), размер [число образцов x число признаков]
# - Целевой массив, массив меток (targets - то, что мы хотим найти) -
# одномерный массив (обычно) [1 x число образцов] - данные, которые мы хотим предсказать
# на основе имеющихся данных
# - Зависимые (метка) и независимые переменные (признаки)

# ### Процесс построения системы машинного обучения
# 1. Предварительная обработка
# - На вход поступают необработанные данные и метки
# - Происходит выбор признаков, их масштабирование при необходимости
# - Понижение размерности при возможности (линейная зависимость, сильная корреляция)
# - Выборка образцов
# - На выход поступает набор данных: обучающий и тестовый наборы
# 2. Обучение модели
# - Выбор модели
# - Перекрестная проверка
# - Метрики эффективности
# - Оптимизация гиперпараметров. Параметры, которые получаются не из данных,
# а являются настраиваемыми характеристиками модели
# 3. Оценка и формирование финальной модели
# 4. Прогнозирование (использование модели)

# ### Библиотека SciKit-learn
# 1. Выбираем класс модели
# 2. Устанавливаем гиперпараметры модели
# 3. Создаем матрицу признаков и целевой массив
# 4. Обучение модели fit()
# 5. Применение модели к новым данным
# - predict() (с учителем)
# - predict() или transform() (без учителя)

# 1. Математическая основа
# 2. Проведение вычислений, написание алгоритмов
# 3. Атомарные задачи
# 4. Собственные силы
# 5. Библиотеки (SciKit)

# ## Обучение с учителем. Линейная регрессия
# ### Простая линейная регрессия
# y = ax + b
# 
# y = a1x1 + a2x2 + ... + b

# In[179]:


import matplotlib.pyplot as plt
import numpy as np

# I
np.random.seed(1)
x = 10 * np.random.rand(50)
y = 2*x - 1 + np.random.randn(50)

plt.scatter(x,y)

# II
# 1. Выбираем класс модели
from sklearn.linear_model import LinearRegression

# 2. Устанавливаем гиперпараметры модели
# model = LinearRegression(fit_intercept=False)
model = LinearRegression()

# 3. Создаем матрицу признаков и целевой массив
# print(x.shape,y.shape)
X = x[:,np.newaxis]

# 4. Обучение модели fit()
model.fit(X,y)
print(model.coef_[0])
print(model.intercept_)
x_ = np.linspace(0, 10, 30)
y_ = model.coef_[0]*x_ + model.intercept_
plt.plot(x_,y_)

# 5. Применение модели к новым данным
xfit = np.linspace(-10, 10, 5)
yfit = model.predict(xfit[:,np.newaxis])
plt.scatter(xfit,yfit)

